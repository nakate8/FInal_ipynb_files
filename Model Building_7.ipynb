{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c230f480-c51a-4852-a348-f89ff2948ed2",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160feeb2-1b8c-4001-93b2-a2d12603d9f2",
   "metadata": {},
   "source": [
    "## XGBoost Classifier with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edc313-4ba8-46a4-a3af-100b4d082f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec9412-b15e-4391-953d-b92323eb5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost Classifier with class weights\n",
    "xgb_model_weighted = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=len(y_train) / (2 * sum(y_train))  # Example: Adjust based on class imbalance\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb_model_weighted.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_weighted = xgb_model_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score with Class Weights:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"Classification Report with Class Weights:\\n\", classification_report(y_test, y_pred_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef965d82-e0ff-4d5d-8d6d-5a3c3956c439",
   "metadata": {},
   "source": [
    "## Logistic Regression with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38efa8-c8b8-4e40-9e2c-54f044e7f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Logistic Regression with class weights\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Accuracy Score with Logistic Regression:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report with Logistic Regression:\\n\", classification_report(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c868ef4-ff6b-4e7b-ad65-eb5dc59fa831",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8bc1e-ef5c-4c38-b5c8-1f02f882f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Accuracy Score with Gradient Boosting:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Classification Report with Gradient Boosting:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d01e1-6cf2-4d2e-a18e-5a02362473aa",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa83b80-1afa-42bf-80e4-c4552f2d4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Naive Bayes\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Accuracy Score with Naive Bayes:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report with Naive Bayes:\\n\", classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be062d-6edc-4695-ba8f-35663ca5fcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7607e3-8743-48f7-b103-959d8280dd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d358ad1-8c3d-43f7-9a4e-a49392c3a65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
