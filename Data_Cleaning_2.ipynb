{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7850ca-05cd-4fa5-b904-2ae012b67fbb",
   "metadata": {},
   "source": [
    "## Class Distribution Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ef390-62d6-466b-abb0-c398c1503314",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b623b7d9-0ef7-4e4a-8ea1-6b9a6e1298ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0da7-28cb-43a3-95d2-359483a4d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "\n",
    "# Calculate the number of null values for each column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of null values for each column\n",
    "null_percentage = (null_counts / total_rows) * 100\n",
    "\n",
    "# Display the percentage of null values\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d71931-4e2f-4921-85ea-8f76281cc697",
   "metadata": {},
   "source": [
    "## Compute Correlation Matrix and heatmap for columns having null values to understand which columns to impute which to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d172d-4e84-4e0c-8707-d57ad5e9cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing = [\n",
    "    'MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "    'ClimateChange', 'Siltation', 'AgriculturalPractices',\n",
    "    'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "    'CoastalVulnerability', 'DeterioratingInfrastructure',\n",
    "    'PopulationScore', 'WetlandLoss', 'InadequatePlanning',\n",
    "    'ClimateAnthropogenicInteraction', 'InfrastructurePreventionInteraction'\n",
    "]\n",
    "\n",
    "correlation_matrix = df[columns_with_missing + ['FloodProbability']].corr()\n",
    "\n",
    "(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66112aa-8155-4e95-b416-b1cdf9bbbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f', linewidths=.5)\n",
    "plt.title('Correlation Matrix with FloodProbability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6dd8b-0ae7-4403-a45d-100866cde6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rationale for Not Dropping Null Values Based on Correlation Analysis\n",
    "In our analysis, we carefully examined the correlation matrix to guide our decision on handling null values. The decision not to drop rows with null values from certain columns was influenced by the following considerations:\n",
    "\n",
    "Columns with Stronger Correlations:\n",
    "\n",
    "ClimateAnthropogenicInteraction and InfrastructurePreventionInteraction: These columns exhibit strong correlations with the target variable, FloodProbability. Their imputation is crucial as they have a significant impact on flood predictions.\n",
    "Less Impactful Columns:\n",
    "\n",
    "Encroachments, PoliticalFactors, AgriculturalPractices, WetlandLoss, and InadequatePlanning: Although these columns have null values, their lower correlation with the target variable and other predictors suggests they have less impact on the overall model performance. Dropping rows with null values in these columns helps maintain a cleaner dataset while minimizing loss of important data.\n",
    "Data Preservation:\n",
    "\n",
    "Dropping rows with null values from columns that are less correlated but still potentially relevant can lead to significant data loss, affecting the overall integrity of the dataset. Imputation methods are employed to preserve as much data as possible, ensuring that the analysis remains comprehensive and robust.\n",
    "By focusing on imputation for columns with higher correlation and impact, we aim to maintain the dataset's integrity while addressing null values in a way that enhances model accuracy and reliability.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e777520-5477-4766-b61b-471afa36880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Encroachments', 'PoliticalFactors', 'AgriculturalPractices', 'WetlandLoss', 'InadequatePlanning']\n",
    "df.dropna(subset=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469bb33-4067-4595-81cb-7f80f88a2c1b",
   "metadata": {},
   "source": [
    "## 1.Median Imputation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e69237-713a-4fc9-bd31-267e0679e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_columns = ['Deforestation', 'Landslides', 'Watersheds']\n",
    "df[median_columns] = df[median_columns].fillna(df[median_columns].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899416e-20d2-43a3-926b-562e183138de",
   "metadata": {},
   "source": [
    "## 2.Linear Interpolation Imputation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4161ac-a13e-4916-9258-a941a19ffe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_columns = ['Urbanization', 'DamsQuality']\n",
    "df[interpolate_columns] = df[interpolate_columns].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f818da-bd41-4e2c-8c00-69b414d3777d",
   "metadata": {},
   "source": [
    "## 3.Iterative Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41541500-4fe0-464b-901e-51a830df287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute_iterative = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'CoastalVulnerability', 'ClimateAnthropogenicInteraction']\n",
    "iterative_imputer = IterativeImputer()\n",
    "\n",
    "df[columns_to_impute_iterative] = iterative_imputer.fit_transform(df[columns_to_impute_iterative])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d3c4f-7319-44da-8109-6b0ed6705a37",
   "metadata": {},
   "source": [
    "## 4.Multiple Imputation by Chained Equations (MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7890a-f3cb-4037-aa06-94d4bf31e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute_mice = ['ClimateChange', 'Siltation', 'DeterioratingInfrastructure', 'InfrastructurePreventionInteraction',\n",
    "                          'IneffectiveDisasterPreparedness', 'DrainageSystems', 'PopulationScore']\n",
    "mice_imputer = IterativeImputer() \n",
    "df[columns_to_impute_mice] = mice_imputer.fit_transform(df[columns_to_impute_mice])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa01106-533d-42f3-8b19-7bed5c11fee7",
   "metadata": {},
   "source": [
    "## outliers\n",
    "## statistical methods\n",
    "## z-score\n",
    "## because data is approximately normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68d9e0-ff83-4fbb-b8f6-5b4dbde28364",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = len(columns)\n",
    "num_rows = (num_columns // 3) + int(num_columns % 3 != 0)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(18, 4 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each column\n",
    "for i, column in enumerate(columns):\n",
    "    sns.histplot(df[column].dropna(), bins=30, kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7075fb9-d21b-4891-8097-6b456c1ad608",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "           'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "           'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "           'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "           'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "           'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "           'InadequatePlanning', 'PoliticalFactors', 'ClimateAnthropogenicInteraction',\n",
    "           'InfrastructurePreventionInteraction']\n",
    "\n",
    "def detect_outliers_zscore(df, columns, threshold=3):\n",
    "    outliers = {}\n",
    "    for column in columns:\n",
    "        z_scores = np.abs(stats.zscore(df[column].dropna()))\n",
    "        outliers[column] = df[column][z_scores > threshold].index.tolist()\n",
    "    return outliers\n",
    "    \n",
    "zscore_outliers = detect_outliers_zscore(df, columns)\n",
    "#zscore_outliers\n",
    "for column, indices in zscore_outliers.items():\n",
    "    print(f\"{column}: {len(indices)} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02144536-326a-487d-9be4-63fef6bfad89",
   "metadata": {},
   "source": [
    "## dropping outliers based on z-score of columns and domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7381e2-1889-4c97-981f-f60f2869f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "           'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "           'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "           'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "           'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "           'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "           'InadequatePlanning', 'PoliticalFactors', 'ClimateAnthropogenicInteraction',\n",
    "           'InfrastructurePreventionInteraction']\n",
    "\n",
    "outliers_to_drop = {\n",
    "    'MonsoonIntensity': 5,\n",
    "    'TopographyDrainage': 2833,\n",
    "    'RiverManagement': 7608,\n",
    "    'Deforestation': 0,\n",
    "    'Urbanization': 3022,\n",
    "    'ClimateChange': 4793,\n",
    "    'DamsQuality': 3123,\n",
    "    'Siltation': 2949,\n",
    "    'AgriculturalPractices': 2773,\n",
    "    'Encroachments': 3033,\n",
    "    'IneffectiveDisasterPreparedness': 4872,\n",
    "    'DrainageSystems': 5334,\n",
    "    'CoastalVulnerability': 5573,\n",
    "    'Landslides': 2807,\n",
    "    'Watersheds': 2986,\n",
    "    'DeterioratingInfrastructure': 5009,\n",
    "    'PopulationScore': 5134,\n",
    "    'WetlandLoss': 0,\n",
    "    'InadequatePlanning': 0,\n",
    "    'PoliticalFactors': 0,\n",
    "    'ClimateAnthropogenicInteraction': 6194,\n",
    "    'InfrastructurePreventionInteraction': 7300\n",
    "}\n",
    "\n",
    "def drop_outliers_zscore(df, columns, outliers_to_drop):\n",
    "    for column in columns:\n",
    "        if outliers_to_drop.get(column, 0) > 0:\n",
    "            # Calculate Z-Scores\n",
    "            z_scores = stats.zscore(df[column].dropna())\n",
    "            z_scores_df = pd.DataFrame({\n",
    "                'index': df[column].dropna().index,\n",
    "                'z_score': z_scores\n",
    "            })\n",
    "        \n",
    "            top_outliers = z_scores_df.reindex(z_scores_df['z_score'].abs().sort_values(ascending=False).index)\n",
    "            top_outliers = top_outliers.head(outliers_to_drop[column])\n",
    "            # Drop the rows with the top N outliers\n",
    "            df.drop(index=top_outliers['index'], inplace=True)\n",
    "\n",
    "drop_outliers_zscore(df, columns, outliers_to_drop)\n",
    "\n",
    "print(\"Updated DataFrame shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62706d-bcda-4499-9ad0-a24f455ffb08",
   "metadata": {},
   "source": [
    "## SimpleImputer with Mean Imputation for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccff2d-7e7c-4853-b4d9-d0dd9fc35e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute = ['TopographyDrainage', 'Urbanization', 'DamsQuality', \n",
    "                      'Siltation', 'AgriculturalPractices', 'Landslides', \n",
    "                      'Watersheds', 'InadequatePlanning', 'ClimateAnthropogenicInteraction', \n",
    "                      'InfrastructurePreventionInteraction']\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df[columns_to_impute] = mean_imputer.fit_transform(df[columns_to_impute])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a4ec3-803b-46cf-b36f-67ae86ad6f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a63e7b-1c03-4815-8cdc-9201f8fe13ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244a832-4bba-4685-9404-33c9a020077d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063caf30-0888-4b28-ac04-9aa2a041b69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f553ec-d508-4426-bc54-a83f02fe3fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353b3fe-046b-4c47-b7a0-caab1e6bb3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6ea01-00e7-41fe-99b2-58cbe9ba7ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
